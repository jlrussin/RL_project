# Autoencoder for state embedding

import torch.nn as nn

class VAE(nn.Module):
    def __init__(self,embedding_size):
        super(VAE, self).__init__()
        """
        TODO: build variational autoencoder as described in MFEC paper, or copy
              from github somewhere if you can find it?
        """
    def forward(self,observation):
        """
        TODO
        """
        return embedding
